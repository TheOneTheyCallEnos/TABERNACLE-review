#!/usr/bin/env python3
"""
TABERNACLE Link Diagnostics Script
Scans all .md files, checks LINKAGE blocks, verifies links, identifies orphans.

Refactored 2026-01-15: Now uses centralized config and shared utilities.
"""

import os
import re
from pathlib import Path
from collections import defaultdict
from datetime import datetime
from typing import Optional, List, Dict

# --- CENTRALIZED CONFIG ---
from tabernacle_config import (
    BASE_DIR as TABERNACLE_ROOT,
    SKIP_DIRECTORIES as EXCLUDE_DIRS,
    TRANSIENT_FILES,
    EXAMPLE_LINK_PATTERNS,
)

# --- SHARED UTILITIES ---
from tabernacle_utils import (
    is_valid_wiki_link,
    extract_wiki_links as _extract_wiki_links,
    resolve_link as _resolve_link,
    has_linkage_block as _has_linkage_block,
)

# Local overrides for backward compatibility
EXCLUDE_FILES = {
    "_LINK_DIAGNOSIS.md",    # Meta-file that lists links as content
    "_LINK_FIXES.md",        # Meta-file that lists links as content  
    "apply_link_fixes.md",   # Contains example links
    "diagnose_links.md",     # Contains example links
    "STRUCTURAL_INTEGRITY_REPORT.md",  # Contains example/template links
}

# Extended transient files for diagnose_links
TRANSIENT_FILES = TRANSIENT_FILES | {
    "CURRENT_STATE.md",       # Composite dashboard, auto-generated
    "DAEMON_REFLECTION.md",   # Auto-generated by daemon
    "_GRAPH_ATLAS.md",        # Auto-generated graph metrics
    "_LINK_DIAGNOSIS.md",     # Auto-generated diagnosis
    "_LINK_FIXES.md",         # Auto-generated fixes
    "_VITALS_REPORT.md",      # Auto-generated health report
    "NIGHT_DAEMON_HANDOFF.md", # Auto-generated
    "NIGHT_SYNTHESIS.md",     # Auto-generated
}

LARGE_FILE_THRESHOLD = 100 * 1024  # 100KB

def find_all_md_files(root: Path) -> List[Path]:
    """Recursively find all .md files, excluding certain directories."""
    md_files = []
    for dirpath, dirnames, filenames in os.walk(root):
        # Remove excluded directories from search
        dirnames[:] = [d for d in dirnames if d not in EXCLUDE_DIRS]

        for filename in filenames:
            if filename.endswith(".md") and filename not in EXCLUDE_FILES:
                md_files.append(Path(dirpath) / filename)
    return md_files

def get_file_size(path: Path) -> int:
    """Get file size in bytes."""
    try:
        return path.stat().st_size
    except:
        return 0

# --- LINK UTILITIES (delegating to tabernacle_utils) ---
def has_linkage_block(content: str) -> bool:
    """Check if file has a LINKAGE block. Delegates to shared utility."""
    return _has_linkage_block(content)

def extract_wiki_links(content: str) -> List[str]:
    """Extract all [[wiki-style]] links. Delegates to shared utility."""
    return _extract_wiki_links(content)

def resolve_link(source_file: Path, link: str) -> Optional[Path]:
    """Resolve a wiki-style link. Delegates to shared utility."""
    return _resolve_link(source_file, link)

def analyze_file(file_path: Path) -> Dict:
    """Analyze a single markdown file."""
    result = {
        "path": file_path,
        "relative_path": file_path.relative_to(TABERNACLE_ROOT),
        "size": get_file_size(file_path),
        "has_linkage": False,
        "links": [],
        "broken_links": [],
        "valid_links": [],
        "error": None,
    }

    try:
        # Read file content
        content = file_path.read_text(encoding="utf-8", errors="replace")

        # Check for LINKAGE block
        result["has_linkage"] = has_linkage_block(content)

        # Extract and verify links
        links = extract_wiki_links(content)
        result["links"] = links

        for link in links:
            resolved = resolve_link(file_path, link)
            if resolved:
                result["valid_links"].append({
                    "link": link,
                    "resolved": resolved.relative_to(TABERNACLE_ROOT) if resolved.is_relative_to(TABERNACLE_ROOT) else resolved
                })
            else:
                result["broken_links"].append(link)

    except Exception as e:
        result["error"] = str(e)

    return result

def build_graph(analyses: List[Dict]) -> Dict:
    """Build incoming/outgoing link graph."""
    # Map relative paths to their analysis
    path_to_analysis = {}
    for a in analyses:
        path_to_analysis[str(a["relative_path"])] = a

    # Track incoming links
    incoming = defaultdict(list)

    for a in analyses:
        source = str(a["relative_path"])
        for link_info in a["valid_links"]:
            target = str(link_info["resolved"])
            incoming[target].append(source)

    return {
        "path_to_analysis": path_to_analysis,
        "incoming": dict(incoming),
    }

def identify_orphans(analyses: List[Dict], graph: Dict) -> List[str]:
    """Find files with no incoming links (except index/root files)."""
    # Files that are okay to have no incoming links
    root_files = {
        "00_NEXUS/CURRENT_STATE.md",
        "00_NEXUS/_GRAPH_ATLAS.md",
        "00_NEXUS/_LINK_DIAGNOSIS.md",
        "00_NEXUS/_LINK_FIXES.md",
        "README.md",
    }

    orphans = []
    for a in analyses:
        rel_path = str(a["relative_path"])
        # Skip files in CRYPT (archives), TASKS, and logs
        if any(skip in rel_path for skip in ["05_CRYPT/", "TASKS/", "logs/", ".repair_backups/"]):
            continue
        if rel_path in root_files:
            continue
        if rel_path not in graph["incoming"]:
            orphans.append(rel_path)

    return orphans

def generate_diagnosis_report(analyses: List[Dict], graph: Dict, orphans: List[str]) -> str:
    """Generate the diagnosis markdown report."""

    # Gather statistics
    total_files = len(analyses)
    files_with_linkage = sum(1 for a in analyses if a["has_linkage"])
    files_without_linkage = [a for a in analyses if not a["has_linkage"]]
    all_broken_links = [(a["relative_path"], link) for a in analyses for link in a["broken_links"]]
    large_files = [a for a in analyses if a["size"] > LARGE_FILE_THRESHOLD]
    files_with_errors = [a for a in analyses if a["error"]]

    # Filter out CRYPT/TASKS/logs AND transient files for "missing linkage" report
    active_files_without_linkage = [
        a for a in files_without_linkage
        if not any(skip in str(a["relative_path"]) for skip in ["05_CRYPT/", "TASKS/", "logs/", "scripts/", ".repair_backups/"])
        and a["relative_path"].name not in TRANSIENT_FILES
    ]

    # Pre-calculate active vs archive broken for summary
    active_broken_count = len([(src, link) for src, link in all_broken_links 
                               if not any(skip in str(src) for skip in ["05_CRYPT/", "TASKS/", "logs/", "scripts/", ".repair_backups/"])])
    archive_broken_count = len(all_broken_links) - active_broken_count

    report = f"""# TABERNACLE Link Diagnosis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Script:** `scripts/diagnose_links.py`

---

## Summary

| Metric | Count |
|--------|-------|
| Total .md files scanned | {total_files} |
| Files with LINKAGE block | {files_with_linkage} |
| Files missing LINKAGE (active quadrants) | {len(active_files_without_linkage)} |
| Broken links (active quadrants) | {active_broken_count} |
| Broken links (archives - acceptable) | {archive_broken_count} |
| Orphan files (no incoming links) | {len(orphans)} |
| Large files (>100KB) | {len(large_files)} |
| Files with read errors | {len(files_with_errors)} |

---

## Files Missing LINKAGE Blocks (Active Quadrants)

These files in 00_NEXUS through 04_LR_LAW are missing LINKAGE blocks:

"""

    if active_files_without_linkage:
        for a in sorted(active_files_without_linkage, key=lambda x: str(x["relative_path"])):
            report += f"- `{a['relative_path']}`\n"
    else:
        report += "*None found - all active files have LINKAGE blocks!*\n"

    # Separate active vs archive broken links
    active_broken = [(src, link) for src, link in all_broken_links 
                     if not any(skip in str(src) for skip in ["05_CRYPT/", "TASKS/", "logs/", "scripts/", ".repair_backups/"])]
    archive_broken = [(src, link) for src, link in all_broken_links 
                      if any(skip in str(src) for skip in ["05_CRYPT/", "TASKS/", "logs/", "scripts/", ".repair_backups/"])]

    report += """
---

## Broken Links (Active Quadrants)

Links in 00_NEXUS through 04_LR_LAW that point to non-existent files:

"""

    if active_broken:
        for source, link in sorted(active_broken, key=lambda x: str(x[0])):
            report += f"- `{source}` â†’ `[[{link}]]`\n"
    else:
        report += "*None found - all active links resolve correctly!*\n"

    report += f"""
---

## Broken Links (Archives/Scripts)

*{len(archive_broken)} broken links in CRYPT/TASKS/logs/scripts - acceptable as historical references.*
"""

    report += """
---

## Orphan Files

Files with no incoming links (excluding CRYPT/TASKS/logs):

"""

    if orphans:
        for orphan in sorted(orphans):
            report += f"- `{orphan}`\n"
    else:
        report += "*None found - all files are connected!*\n"

    report += """
---

## Large Files (>100KB)

These files may need special handling (no auto-edits):

"""

    if large_files:
        for a in sorted(large_files, key=lambda x: x["size"], reverse=True):
            size_kb = a["size"] / 1024
            report += f"- `{a['relative_path']}` ({size_kb:.1f} KB)\n"
    else:
        report += "*None found*\n"

    report += """
---

## Files With Read Errors

"""

    if files_with_errors:
        for a in files_with_errors:
            report += f"- `{a['relative_path']}`: {a['error']}\n"
    else:
        report += "*None - all files read successfully*\n"

    report += """
---

## Graph Statistics

"""

    # Find most connected files
    incoming_counts = [(path, len(sources)) for path, sources in graph["incoming"].items()]
    incoming_counts.sort(key=lambda x: x[1], reverse=True)

    report += "### Most Connected Files (by incoming links)\n\n"
    for path, count in incoming_counts[:10]:
        report += f"- `{path}`: {count} incoming links\n"

    report += "\n---\n\n*End of diagnosis report*\n"

    return report

def generate_fixes_report(analyses: List[Dict], orphans: List[str]) -> str:
    """Generate proposed fixes for review."""

    # Filter for active files needing linkage (excluding transient/auto-generated)
    files_without_linkage = [
        a for a in analyses
        if not a["has_linkage"]
        and not any(skip in str(a["relative_path"]) for skip in ["05_CRYPT/", "TASKS/", "logs/", "scripts/", ".repair_backups/"])
        and a["relative_path"].name not in TRANSIENT_FILES
        and a["size"] < LARGE_FILE_THRESHOLD  # Don't propose fixes for large files
    ]

    report = f"""# TABERNACLE Link Fixes - Proposed

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Status:** REVIEW REQUIRED - Do not auto-apply

---

## Proposed LINKAGE Blocks

For each file missing a LINKAGE block, here's a proposed addition:

"""

    if not files_without_linkage:
        report += "*No fixes needed - all active files have LINKAGE blocks!*\n"
    else:
        for a in sorted(files_without_linkage, key=lambda x: str(x["relative_path"])):
            rel_path = str(a["relative_path"])

            # Determine quadrant and suggest hub
            if rel_path.startswith("00_NEXUS/"):
                hub = "00_NEXUS/CURRENT_STATE.md"
                anchor = "00_NEXUS/_GRAPH_ATLAS.md"
            elif rel_path.startswith("01_UL_INTENT/"):
                hub = "00_NEXUS/CURRENT_STATE.md"
                anchor = "01_UL_INTENT/PROMPT_PRIME.md"
            elif rel_path.startswith("02_UR_STRUCTURE/"):
                hub = "00_NEXUS/CURRENT_STATE.md"
                if "METHODS" in rel_path:
                    anchor = "02_UR_STRUCTURE/METHODS/INDEX.md"
                elif "SKILLS" in rel_path:
                    anchor = "02_UR_STRUCTURE/SKILLS/SKILL.md"
                else:
                    anchor = "02_UR_STRUCTURE/Z-GENOME.md"
            elif rel_path.startswith("03_LL_RELATION/"):
                hub = "00_NEXUS/CURRENT_STATE.md"
                anchor = "03_LL_RELATION/MEMORY_ROOT.md"
            elif rel_path.startswith("04_LR_LAW/"):
                hub = "00_NEXUS/CURRENT_STATE.md"
                anchor = "04_LR_LAW/CANON/INDEX.md"
            else:
                hub = "00_NEXUS/CURRENT_STATE.md"
                anchor = "README.md"

            report += f"""
### `{rel_path}`

**Add to end of file:**

```markdown

## LINKAGE (The Circuit)

| Direction | Seed |
|-----------|------|
| Hub | [[{hub}]] |
| Anchor | [[{anchor}]] |
```

---
"""

    report += """
## Orphan Integration

These orphan files need incoming links from other files:

"""

    if orphans:
        for orphan in sorted(orphans):
            report += f"- `{orphan}` - needs to be linked FROM another file\n"
    else:
        report += "*No orphans to integrate*\n"

    report += """
---

## Instructions

1. Review each proposed LINKAGE block above
2. Adjust Anchor links to more appropriate related files if needed
3. Manually add the blocks to files (or request Claude Code to apply specific ones)
4. For orphans, add links TO these files from related documents

---

*End of proposed fixes*
"""

    return report

def main():
    print("TABERNACLE Link Diagnostics")
    print("=" * 40)

    # Phase 1: Scan all files
    print("\n[1/4] Finding all .md files...")
    md_files = find_all_md_files(TABERNACLE_ROOT)
    print(f"      Found {len(md_files)} markdown files")

    print("\n[2/4] Analyzing each file...")
    analyses = []
    for i, file_path in enumerate(md_files):
        if i % 20 == 0:
            print(f"      Processing {i+1}/{len(md_files)}...")
        analyses.append(analyze_file(file_path))
    print(f"      Analyzed {len(analyses)} files")

    # Phase 2: Build graph
    print("\n[3/4] Building link graph...")
    graph = build_graph(analyses)
    orphans = identify_orphans(analyses, graph)
    print(f"      Found {len(orphans)} orphan files")

    # Phase 3: Generate reports
    print("\n[4/4] Generating reports...")

    diagnosis_report = generate_diagnosis_report(analyses, graph, orphans)
    diagnosis_path = TABERNACLE_ROOT / "00_NEXUS" / "_LINK_DIAGNOSIS.md"
    diagnosis_path.write_text(diagnosis_report, encoding="utf-8")
    print(f"      Written: {diagnosis_path}")

    fixes_report = generate_fixes_report(analyses, orphans)
    fixes_path = TABERNACLE_ROOT / "00_NEXUS" / "_LINK_FIXES.md"
    fixes_path.write_text(fixes_report, encoding="utf-8")
    print(f"      Written: {fixes_path}")

    print("\n" + "=" * 40)
    print("COMPLETE")
    print(f"\nReports generated:")
    print(f"  - {diagnosis_path}")
    print(f"  - {fixes_path}")

    # Print quick summary
    files_with_linkage = sum(1 for a in analyses if a["has_linkage"])
    all_broken = sum(len(a["broken_links"]) for a in analyses)
    print(f"\nQuick Summary:")
    print(f"  - {files_with_linkage}/{len(analyses)} files have LINKAGE blocks")
    print(f"  - {all_broken} broken links found")
    print(f"  - {len(orphans)} orphan files")

if __name__ == "__main__":
    main()
